{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Lightning\n",
    "\n",
    "Converting our ImageNet training with Nvidia DALI to PyTorch Lightning helps us organize the code\n",
    "and allows us to reuse nice modularized components offered by the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wed Nov 24 09:39:41 2021: [unset]:_pmi_alps_init:alps_get_placement_info returned with error -1\n",
      "Wed Nov 24 09:39:41 2021: [unset]:_pmi_init:_pmi_alps_init returned -1\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from simple_cnn import SimpleCNN\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Lightning model\n",
    "\n",
    "The LightningModule at [train_imagenet_pl.py](./train_imagenet_pl.py) also define the DALI dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/daint/UES/jenkins/7.0.UP02-20.11/gpu/easybuild/software/PyTorch/1.9.0-CrayGNU-20.11/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "LtngModel                                     --                        --\n",
       "├─ResNet: 1-1                                 [256, 1000]               --\n",
       "│    └─Conv2d: 2-1                            [256, 64, 112, 112]       9,408\n",
       "│    └─BatchNorm2d: 2-2                       [256, 64, 112, 112]       128\n",
       "│    └─ReLU: 2-3                              [256, 64, 112, 112]       --\n",
       "│    └─MaxPool2d: 2-4                         [256, 64, 56, 56]         --\n",
       "│    └─Sequential: 2-5                        [256, 64, 56, 56]         --\n",
       "│    │    └─BasicBlock: 3-1                   [256, 64, 56, 56]         73,984\n",
       "│    │    └─BasicBlock: 3-2                   [256, 64, 56, 56]         73,984\n",
       "│    └─Sequential: 2-6                        [256, 128, 28, 28]        --\n",
       "│    │    └─BasicBlock: 3-3                   [256, 128, 28, 28]        230,144\n",
       "│    │    └─BasicBlock: 3-4                   [256, 128, 28, 28]        295,424\n",
       "│    └─Sequential: 2-7                        [256, 256, 14, 14]        --\n",
       "│    │    └─BasicBlock: 3-5                   [256, 256, 14, 14]        919,040\n",
       "│    │    └─BasicBlock: 3-6                   [256, 256, 14, 14]        1,180,672\n",
       "│    └─Sequential: 2-8                        [256, 512, 7, 7]          --\n",
       "│    │    └─BasicBlock: 3-7                   [256, 512, 7, 7]          3,673,088\n",
       "│    │    └─BasicBlock: 3-8                   [256, 512, 7, 7]          4,720,640\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 [256, 512, 1, 1]          --\n",
       "│    └─Linear: 2-10                           [256, 1000]               513,000\n",
       "===============================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 464.41\n",
       "===============================================================================================\n",
       "Input size (MB): 154.14\n",
       "Forward/backward pass size (MB): 10175.33\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 10376.23\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_imagenet_pl import LtngModel\n",
    "\n",
    "model = LtngModel(\n",
    "    data_path='/scratch/snx3000/datasets/imagenet/ILSVRC2012_1k',\n",
    "    arch='resnet18',\n",
    "    optimizer='AdamW',\n",
    "    batch_size=32,\n",
    "    learning_rate=2e-4,\n",
    "    epochs=2,\n",
    ")\n",
    "\n",
    "summary(model, input_size=(model.hparams.batch_size, 3, model.hparams.image_size, model.hparams.image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trainer and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | net  | ResNet | 11.7 M\n",
      "--------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.758    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a281d434204c508daaaee298386a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    default_root_dir=os.path.join(os.environ['SCRATCH'], 'lightning_run'),\n",
    "    limit_train_batches=50,\n",
    "    limit_val_batches=50,\n",
    "    max_epochs=model.hparams.epochs,\n",
    "    replace_sampler_ddp=False,  # disable sampler as DALI shards the data itself\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistributedDataParallel in PyTorch Lightning¶\n",
    "\n",
    "```python\n",
    "trainer = Trainer(gpus=1, num_nodes=2, strategy=\"ddp\", ...)\n",
    "```\n",
    "\n",
    "Supports SLURM by default, so there is no need to setup any environment variables\n",
    "\n",
    "Note: This will not work in the Jupyter notebook, please see use `sbatch` [train_imagenet_pl.sh](./train_imagenet_pl.sh)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSpeedPlugin for PyTorch Lightning\n",
    "\n",
    "https://pytorch-lightning.readthedocs.io/en/stable/advanced/advanced_gpu.html#deepspeed\n",
    "\n",
    "Available in PyTorch Lightning through a strategy plugin\n",
    "\n",
    "```python\n",
    "trainer = Trainer(gpus=1, strategy=\"deepspeed_stage_2\", precision=16, ...)\n",
    "```\n",
    "\n",
    "Or use the [plugin](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.plugins.training_type.DeepSpeedPlugin.html) directly for additional options:\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.plugins import DeepSpeedPlugin\n",
    "\n",
    "ds_plugin = DeepSpeedPlugin(\n",
    "    stage=3,\n",
    "    offload_optimizer=True,\n",
    "    offload_parameters=True,\n",
    "    remote_device=\"nvme\",\n",
    "    offload_params_device=\"nvme\",\n",
    "    offload_optimizer_device=\"nvme\",\n",
    "    nvme_path=\"/local_nvme\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=4, strategy=ds_plugin, precision=16, ...)\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed",
   "language": "python",
   "name": "deepspeed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
