{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ed091b-e0c4-44f7-a41e-9c9e1c6f25c4",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874c513-6970-44ad-bce4-66555ae31a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c80ff4-1be8-4816-88e3-851cedd139a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((8, 28, 28))   # (batch_size, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581934cc-9899-4c94-8af7-bf1c88a4c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten input images            (28, 28) -> (784,)\n",
    "        x = self.fc1(x)          # Apply Fully Connected layer 1   (784,)   -> (128,)\n",
    "        x = self.relu1(x)        # Apply ReLU activation Function  (784,)\n",
    "        x = self.fc2(x)          # Apply Fully Connected layer 2   (128,)   -> (64,)\n",
    "        x = self.relu2(x)        # Apply ReLU activation Function  (64,)\n",
    "        x = self.fc3(x)          # Apply Fully Connected layer 3   (64,)    -> (10,)\n",
    "        x = F.softmax(x, dim=1)  # Apply Softmax function          (10,)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5cd26-d594-4d47-b09f-55568c6477b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9913d-0e9c-41a1-87f1-2f88aa65cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = x.view(-1, 28 * 28)\n",
    "x_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7101c71-00bb-4f1e-9dd8-e2cd2f68c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7af31f-cf25-4d8b-a925-c5d8d13860b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(28 * 28, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42eb76-e861-4610-b917-cdf77a8bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin(x_flat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1aff50-4f64-4e78-aece-2bbf989a9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325ce37-bd0a-448b-8afa-90519a4abad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3226cc-cbd2-4079-a4a8-8de5e4df08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.mm(x_flat, lin.weight.T) + lin.bias\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.3.0",
   "language": "python",
   "name": "pytorch-2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
