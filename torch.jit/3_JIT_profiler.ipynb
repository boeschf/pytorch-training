{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch benchmark, profiler and JIT compiler\n",
    "\n",
    "In this notebook we will see a simple example on how to use the PyTorch benchmark and profiler, and discuss the impact of Just-in-Time compilation on performance of custom functions.\n",
    "We will use the mean squared error loss for its simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '12' # for Numpy and BLAS\n",
    "  \n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils import data\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random scalar data\n",
    "nsamples = 20000\n",
    "nfeat = 500\n",
    "\n",
    "x = np.random.random([nsamples, nfeat])\n",
    "y = np.random.random([nsamples, nfeat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(input, target):\n",
    "    '''\n",
    "    measures the mean squared error (squared L2 norm) between\n",
    "    each element in the input `x` and target :`y`\n",
    "    '''\n",
    "    diff = (input - target)  # WARN: this temporary variable makes this function 10-20% slower in Numpy\n",
    "    return (diff**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.7 ms ± 337 µs per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time the MSE function\n",
    "%timeit -n1 -r100 mse(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch benchmark (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyless Tensors\n",
    "tx = torch.from_numpy(x)\n",
    "ty = torch.from_numpy(y)\n",
    "\n",
    "tx.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 ms ± 1.01 ms per loop (mean ± std. dev. of 100 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(12)\n",
    "\n",
    "%timeit -n1 -r100 mse(tx, ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "cx = tx.to(device)\n",
    "cy = ty.to(device)\n",
    "\n",
    "# %timeit -n1 -r100 mse(cx, cy) ## !!! Wrong way of time GPU functions, without torch.cuda.synchronize()\n",
    "## https://pytorch.org/tutorials/recipes/recipes/benchmark.html#benchmarking-with-torch-utils-benchmark-timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x2aabfba7a7c0>\n",
      "mse(x, y)\n",
      "setup: from __main__ import mse\n",
      "  978.00 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='mse(x, y)',\n",
    "    setup='from __main__ import mse',\n",
    "    globals={'x': cx, 'y': cy})\n",
    "\n",
    "print(t0.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     473.000us        48.56%     473.000us     473.000us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     347.000us        35.63%     347.000us     347.000us             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     153.000us        15.71%     153.000us     153.000us             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us         0.10%       1.000us       1.000us             1  \n",
      "                                       cudaLaunchKernel        99.96%        1.652s        99.96%        1.652s     550.683ms       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                        cudaMemsetAsync         0.00%      11.000us         0.00%      11.000us      11.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize         0.04%     676.000us         0.04%     676.000us     676.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.653s\n",
      "Self CUDA time total: 974.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CUDA]) as prof:\n",
    "    with record_function(\"mse\"):\n",
    "        mse(cx, cy)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "prof.export_chrome_trace(\"mse.trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>cpu_time_total</th>\n",
       "      <th>cuda_time_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cudaLaunchKernel</th>\n",
       "      <td>3</td>\n",
       "      <td>1652050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaDeviceSynchronize</th>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaMemsetAsync</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::vectorized_elementwise_kernel&lt;4, at::native::BinaryFunctor&lt;double, double, double, at::native::AddFunctor&lt;double&gt; &gt;, at::detail::Array&lt;char*, 3&gt; &gt;(int, at::native::BinaryFunctor&lt;double, double, double, at::native::AddFunctor&lt;double&gt; &gt;, at::detail::Array&lt;char*, 3&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::vectorized_elementwise_kernel&lt;4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl&lt;double, double&gt;(at::TensorIteratorBase&amp;, double)::{lambda(double)#1}, at::detail::Array&lt;char*, 2&gt; &gt;(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl&lt;double, double&gt;(at::TensorIteratorBase&amp;, double)::{lambda(double)#1}, at::detail::Array&lt;char*, 2&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::reduce_kernel&lt;512, 1, at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt; &gt;(at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memset (Device)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count cpu_time_total  \\\n",
       "cudaLaunchKernel                                       3        1652050   \n",
       "cudaDeviceSynchronize                                  1            676   \n",
       "cudaMemsetAsync                                        1             11   \n",
       "void at::native::vectorized_elementwise_kernel<...     1              0   \n",
       "void at::native::vectorized_elementwise_kernel<...     1              0   \n",
       "void at::native::reduce_kernel<512, 1, at::nati...     1              0   \n",
       "Memset (Device)                                        1              0   \n",
       "\n",
       "                                                   cuda_time_total  \n",
       "cudaLaunchKernel                                                 0  \n",
       "cudaDeviceSynchronize                                            0  \n",
       "cudaMemsetAsync                                                  0  \n",
       "void at::native::vectorized_elementwise_kernel<...             473  \n",
       "void at::native::vectorized_elementwise_kernel<...             347  \n",
       "void at::native::reduce_kernel<512, 1, at::nati...             153  \n",
       "Memset (Device)                                                  1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({e.key:e.__dict__ for e in prof.key_averages()}).T\n",
    "df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(['cpu_time_total', 'cuda_time_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Just-in-Time compiler\n",
    "\n",
    "https://pytorch.org/docs/stable/jit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripting vs. Tracing\n",
    "\n",
    "- `torch.jit.script` compiles the function or module into TorchScript, using a \\[large\\] subset of Python\n",
    "- `torch.jit.trace` uses the example input to compute a fixed graph, and therefore cannot handle control flow, e.g. if statements and similar conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mse(input: Tensor,\n",
      "    target: Tensor) -> Tensor:\n",
      "  _0 = torch.pow(torch.sub(input, target), 2)\n",
      "  return torch.mean(_0)\n",
      "\n",
      "graph(%input : Double(20000, 500, strides=[500, 1], requires_grad=0, device=cuda:0),\n",
      "      %target : Double(20000, 500, strides=[500, 1], requires_grad=0, device=cuda:0)):\n",
      "  %2 : int = prim::Constant[value=1]() # /tmp/ipykernel_7031/3968975852.py:6:0\n",
      "  %3 : Double(20000, 500, strides=[500, 1], requires_grad=0, device=cuda:0) = aten::sub(%input, %target, %2) # /tmp/ipykernel_7031/3968975852.py:6:0\n",
      "  %4 : int = prim::Constant[value=2]() # /scratch/snx3000/dealmeih/ds/deepspeed-env/lib/python3.8/site-packages/torch/_tensor.py:30:0\n",
      "  %5 : Double(20000, 500, strides=[500, 1], requires_grad=0, device=cuda:0) = aten::pow(%3, %4) # /scratch/snx3000/dealmeih/ds/deepspeed-env/lib/python3.8/site-packages/torch/_tensor.py:30:0\n",
      "  %6 : NoneType = prim::Constant()\n",
      "  %7 : Double(requires_grad=0, device=cuda:0) = aten::mean(%5, %6) # /tmp/ipykernel_7031/3968975852.py:7:0\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @torch.jit.script\n",
    "# def jit_mse(input, target):\n",
    "#     return ((input - target)**2).mean()\n",
    "\n",
    "# jit_mse = torch.jit.script(mse)\n",
    "jit_mse = torch.jit.trace(mse, example_inputs=(cx, cy))\n",
    "print(jit_mse.code)\n",
    "print(jit_mse.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x2aabfb8c44f0>\n",
      "jit_mse(x, y)\n",
      "setup: from __main__ import jit_mse\n",
      "  594.62 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "t1 = benchmark.Timer(\n",
    "    stmt='jit_mse(x, y)',\n",
    "    setup='from __main__ import jit_mse',\n",
    "    globals={'x': cx, 'y': cy})\n",
    "\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          fused_sub_pow         0.00%       0.000us         0.00%       0.000us       0.000us     435.000us        74.11%     435.000us     435.000us             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     151.000us        25.72%     151.000us     151.000us             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us         0.17%       1.000us       1.000us             1  \n",
      "                                        cudaMemsetAsync         3.05%      13.000us         3.05%      13.000us      13.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                       cudaLaunchKernel         3.29%      14.000us         3.29%      14.000us      14.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize        93.66%     399.000us        93.66%     399.000us     399.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 426.000us\n",
      "Self CUDA time total: 587.000us\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>cpu_time_total</th>\n",
       "      <th>cuda_time_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cudaDeviceSynchronize</th>\n",
       "      <td>1</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaLaunchKernel</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaMemsetAsync</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fused_sub_pow</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::reduce_kernel&lt;512, 1, at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt; &gt;(at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memset (Device)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count cpu_time_total  \\\n",
       "cudaDeviceSynchronize                                  1            399   \n",
       "cudaLaunchKernel                                       1             14   \n",
       "cudaMemsetAsync                                        1             13   \n",
       "fused_sub_pow                                          1              0   \n",
       "void at::native::reduce_kernel<512, 1, at::nati...     1              0   \n",
       "Memset (Device)                                        1              0   \n",
       "\n",
       "                                                   cuda_time_total  \n",
       "cudaDeviceSynchronize                                            0  \n",
       "cudaLaunchKernel                                                 0  \n",
       "cudaMemsetAsync                                                  0  \n",
       "fused_sub_pow                                                  435  \n",
       "void at::native::reduce_kernel<512, 1, at::nati...             151  \n",
       "Memset (Device)                                                  1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"jit_mse\"):\n",
    "        jit_mse(cx, cy)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "prof.export_chrome_trace(\"jit_mse.trace.json\")\n",
    "\n",
    "df = pd.DataFrame({e.key:e.__dict__ for e in prof.key_averages()}).T\n",
    "df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(['cpu_time_total', 'cuda_time_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with torch.nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x2aabfb8c4f10>\n",
      "mse_loss(x, y)\n",
      "setup: from torch.nn.functional import mse_loss\n",
      "  631.29 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "## F.mse_loss(cx, cy)\n",
    "assert jit_mse(cx, cy) - F.mse_loss(cx, cy) < 1e-12\n",
    "\n",
    "t2 = benchmark.Timer(\n",
    "    stmt='mse_loss(x, y)',\n",
    "    setup='from torch.nn.functional import mse_loss',\n",
    "    globals={'x': cx, 'y': cy})\n",
    "\n",
    "print(t2.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     472.000us        75.40%     472.000us     472.000us             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     152.000us        24.28%     152.000us     152.000us             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.32%       2.000us       2.000us             1  \n",
      "                                       cudaLaunchKernel        99.96%        1.195s        99.96%        1.195s     597.580ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                        cudaMemsetAsync         0.00%      14.000us         0.00%      14.000us      14.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize         0.04%     444.000us         0.04%     444.000us     444.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.196s\n",
      "Self CUDA time total: 626.000us\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>cpu_time_total</th>\n",
       "      <th>cuda_time_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cudaLaunchKernel</th>\n",
       "      <td>2</td>\n",
       "      <td>1195159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaDeviceSynchronize</th>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cudaMemsetAsync</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::vectorized_elementwise_kernel&lt;4, at::native::mse_kernel_cuda(at::TensorIterator&amp;)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(double, double)#1}, at::detail::Array&lt;char*, 3&gt; &gt;(int, at::native::mse_kernel_cuda(at::TensorIterator&amp;)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(double, double)#1}, at::detail::Array&lt;char*, 3&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>void at::native::reduce_kernel&lt;512, 1, at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt; &gt;(at::native::ReduceOp&lt;double, at::native::MeanOps&lt;double, double&gt;, unsigned int, double, 4&gt;)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memset (Device)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count cpu_time_total  \\\n",
       "cudaLaunchKernel                                       2        1195159   \n",
       "cudaDeviceSynchronize                                  1            444   \n",
       "cudaMemsetAsync                                        1             14   \n",
       "void at::native::vectorized_elementwise_kernel<...     1              0   \n",
       "void at::native::reduce_kernel<512, 1, at::nati...     1              0   \n",
       "Memset (Device)                                        1              0   \n",
       "\n",
       "                                                   cuda_time_total  \n",
       "cudaLaunchKernel                                                 0  \n",
       "cudaDeviceSynchronize                                            0  \n",
       "cudaMemsetAsync                                                  0  \n",
       "void at::native::vectorized_elementwise_kernel<...             472  \n",
       "void at::native::reduce_kernel<512, 1, at::nati...             152  \n",
       "Memset (Device)                                                  2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"mse_loss\"):\n",
    "        F.mse_loss(cx, cy)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "prof.export_chrome_trace(\"mse_loss.trace.json\")\n",
    "\n",
    "df = pd.DataFrame({e.key:e.__dict__ for e in prof.key_averages()}).T\n",
    "df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(['cpu_time_total', 'cuda_time_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple JIT'ed function is actually slightly faster than the PyTorch mse_loss with it's custom CUDA kernel, however, the same is not true in backward pass as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x2aabfba9dd00>\n",
      "jit_mse(x, y).backward()\n",
      "setup: from __main__ import jit_mse\n",
      "  2.04 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x2aabfba9df70>\n",
      "mse_loss(x, y).backward()\n",
      "setup: from torch.nn.functional import mse_loss\n",
      "  1.75 ms\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "var = cx.clone()\n",
    "var.requires_grad = True\n",
    "\n",
    "# warm up\n",
    "jit_mse(var, cy).backward()\n",
    "var.grad = None\n",
    "\n",
    "t3 = benchmark.Timer(\n",
    "    stmt='jit_mse(x, y).backward()',\n",
    "    setup='from __main__ import jit_mse',\n",
    "    globals={'x': var, 'y': cy})\n",
    "\n",
    "t4 = benchmark.Timer(\n",
    "    stmt='mse_loss(x, y).backward()',\n",
    "    setup='from torch.nn.functional import mse_loss',\n",
    "    globals={'x': var, 'y': cy})\n",
    "\n",
    "print(t3.timeit(100))\n",
    "print(t4.timeit(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
