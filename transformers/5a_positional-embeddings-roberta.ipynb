{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380478ca-79e3-49a0-8676-ee8cf2dea112",
   "metadata": {},
   "source": [
    "# RoBERTa's Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9a343-af66-40c2-bbb2-ae0473c41e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd3506-1e3c-4cf0-8663-e000df0a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d8daa-9f35-485e-b07b-c8e62060640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335eded-6900-447f-a760-c0693689b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7eb092-f6c8-45f1-b960-bf49bb7fad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hidden_size  # size of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73fad3-eb6c-45c3-8efc-278e8ecd4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings  # max seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b9cdf-b3d6-44fd-8031-a1fb2d2c7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.arange(0, config.max_position_embeddings)   # seq_len\n",
    "pos_embedding = model.roberta.embeddings.position_embeddings(positions)\n",
    "pos_embedding.shape  # (max_seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659e2c8-6bc4-4796-99f2-4ed64c393925",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(pos_embedding.detach().numpy())\n",
    "plt.imshow(similarity_matrix, cmap='Blues')  #, aspect='auto', extent=[0, max_len, 0, max_len])\n",
    "# plt.colorbar()\n",
    "# plt.title('Position-wise Similarity of Positional Embeddings')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Position')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
