{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380478ca-79e3-49a0-8676-ee8cf2dea112",
   "metadata": {},
   "source": [
    "# BERT's Anatomy Step by Step: Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9a343-af66-40c2-bbb2-ae0473c41e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd3506-1e3c-4cf0-8663-e000df0a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d8daa-9f35-485e-b07b-c8e62060640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9dd74-738a-490e-9dd1-3fb138bfd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe5331-a169-4b77-b19e-11faf31c6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5c19-faa4-47e5-bb34-f4d607ba26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(\"let's tokenize something?\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee421f5c-0ea6-4f77-b15d-82a075a1f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoding.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335eded-6900-447f-a760-c0693689b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.wpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec22971-c5cc-41dd-b609-f0c581d1b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7eb092-f6c8-45f1-b960-bf49bb7fad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hidden_size  # size of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73fad3-eb6c-45c3-8efc-278e8ecd4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings  # max seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4ef01-b588-4750-b3a7-82cb25f296b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_embedding = model.transformer.wte(encoding)\n",
    "seq_embedding.shape   # (batch_size, seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e34ae-5549-4e59-bc7b-e28822b8e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.arange(0, encoding.shape[-1])   # seq_len\n",
    "positions = positions.reshape((1, encoding.shape[-1]))             # make it (batch_size, seq_len)\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700f10c-7997-4df2-9a7f-bbfcb60f6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding_511 = model.transformer.wpe(positions)\n",
    "pos_embedding_511.shape  # (batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3c808-bc75-417b-adc0-b63d1da9404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_embedding + pos_embedding_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b9cdf-b3d6-44fd-8031-a1fb2d2c7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.arange(0, config.max_position_embeddings)   # seq_len\n",
    "positions = positions.reshape((1, config.max_position_embeddings))             # make it (batch_size, seq_len)\n",
    "positions\n",
    "pos_embedding = model.transformer.wpe(positions)[0]\n",
    "pos_embedding.detach().numpy()  # [batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083f4a9-07c0-4e00-b948-54f07d41b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(pos_embedding.detach().numpy())\n",
    "plt.imshow(similarity_matrix, cmap='Blues')  #, aspect='auto', extent=[0, max_len, 0, max_len])\n",
    "# plt.colorbar()\n",
    "plt.title('Position-wise Similarity of Positional Embeddings')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Position')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.3.0",
   "language": "python",
   "name": "pytorch-2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
